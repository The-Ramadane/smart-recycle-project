
# üìÑ Phase 1 : Donn√©es & Entra√Ænement IA (PFE Smart Recycle)

## üìå Objectif
Cette phase couvre la validation des blocs de comp√©tences **Data Engineering (Bloc 1)** et **IA Engineering (Bloc 2)**. L'objectif √©tait de construire un mod√®le de classification d'images capable de reconna√Ætre 6 types de d√©chets pour l'application de tri s√©lectif.

## üõ†Ô∏è Data Engineering (Bloc 1)

### 1. Pr√©paration du Dataset
Nous avons utilis√© le dataset **TrashNet** (¬´ dataset-resized ¬ª) contenant 2527 images r√©parties en 6 classes :
- `cardboard` (Carton)
- `glass` (Verre)
- `metal` (M√©tal)
- `paper` (Papier)
- `plastic` (Plastique)
- `trash` (D√©chets divers)

### 2. Pipeline de Donn√©es
Un script Python d√©di√© (`01_IA_LAB/split_dataset.py`) a √©t√© d√©velopp√© pour automatiser la s√©gr√©gation des donn√©es :
- **R√©partition** : 80% Entra√Ænement / 20% Validation.
- **M√©lange** : Al√©atoire (shuffle) pour √©viter les biais.
- **Structure** : Organisation compatible avec `torchvision.datasets.ImageFolder`.
  - `01_IA_LAB/data/train/` : ~2000 images.
  - `01_IA_LAB/data/val/` : ~500 images.

## üß† Mod√©lisation IA (Bloc 2)

### 1. Choix Technologiques
- **Framework** : PyTorch.
- **Environnement** : Mac Apple Silicon (M1/M2/M3).
- **Acc√©l√©ration Mat√©rielle** : Utilisation du backend **MPS (Metal Performance Shaders)** pour exploiter le GPU Apple, rempla√ßant CUDA (Nvidia).

### 2. Architecture du Mod√®le
Nous avons opt√© pour le **Transfer Learning** (Apprentissage par transfert) :
- **Backbone** : ResNet18 (R√©seau R√©siduel √† 18 couches) pr√©-entra√Æn√© sur ImageNet.
- **Adaptation** : Remplacement de la derni√®re couche *Fully Connected* (`fc`) pour classifier nos 6 classes sp√©cifiques au lieu des 1000 classes d'origine.

### 3. Strat√©gie d'Entra√Ænement
Le notebook `01_IA_LAB/notebooks/training_pytorch.ipynb` impl√©mente le processus suivant :
- **Data Augmentation** (Train) : `RandomResizedCrop` et `RandomHorizontalFlip` pour robustifier le mod√®le.
- **Normalisation** : Utilisation des moyennes et √©carts-types d'ImageNet.
- **Optimiseur** : SGD (Stochastic Gradient Descent) avec Momentum (0.9) et Learning Rate (0.001).
- **Loss Function** : `CrossEntropyLoss`.
- **Scheduler** : `StepLR` (r√©duction du learning rate tous les 7 epochs).

### 4. R√©sultats & Performance
L'entra√Ænement a √©t√© r√©alis√© sur 10 epochs.
- **Epoch 0** : Pr√©cision Val ~76%.
- **Epoch 9** : Pr√©cision Val **~90.5%** (Best Accuracy).
- **Temps d'entra√Ænement** : ~9 minutes sur Mac (MPS).

### 5. Correction Technique (Sp√©cifique Mac)
Un probl√®me de compatibilit√© MPS a √©t√© identifi√© et r√©solu : le tenseur `running_corrects` devait √™tre explicitement converti en `float32` (`.float()`) au lieu de `float64` (`.double()`), car le backend Metal ne supporte pas la double pr√©cision par d√©faut.

## ‚úÖ Livrables Phase 1
- [x] Script de pr√©paration des donn√©es (`split_dataset.py`).
- [x] Notebook d'entra√Ænement valid√© (`training_pytorch.ipynb`).
- [x] Mod√®le export√© (`waste_model.pth`) pr√™t pour l'inf√©rence.
